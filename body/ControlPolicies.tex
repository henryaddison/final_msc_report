\chapter{Control Policies}\label{chapter:control_policy}

This chapter describes the aims of each control policy evaluated in the next chapter by taking a quick dive into the logic behind the control policies.

Five different control policies were studied for this project: RandomChoice, RandomMovement, GearFocussed, SafetyFocussed and Overtaking. A couple of other policies were implemented, DemoChangeSpeed and DemoChangeLane, but as their names suggest these were only created for demonstrating and verfiying the actions.

All policies first check the goal condition (being back at the boathouse after travelling at least the desired distance). After this the policies follow different rules for choosing an action.

\section{RandomChoice}
This policy was created to act as a control in experiments. No effort is made to choose a sensible action. Instead actions are chosen completely at random.

\section{RandomMovement}

More details will follow in the next chapter, but the RandomChoice policy turned out to be too random. The coxes using RandomChoice failed to make any progress because a sixth of the time the cox chose to spin. Spinning takes 60 ticks to complete, fills the river as it does so and does not count towards distance covered. Therefore no boat got very far. The RandomMovement policy was a response to this. This policy will choose to spin if and only if the river is about to run out. Otherwise it will pick at random from the 5 other actions.

\section{GearFocussed}

The GearFocussed policy's main aim is to stick as close to the cox's desired gear and otherwise ignores the environment. The implementation in Java is shown in Listing \ref{listing:control:gear}. This policy will spin if the river is about to run out to ensure it does not get stranded at the lock. Otherwise if the boat's current gear is below the cox's desired gear it will attempt to speed up. If none of the previous conditions hold, it will let the boat run forward. Therefore ideally the cox will try and speed up to match the cox's desired gear and then stay in it. The cox does not want to exceed the desired gear since this is as bad as travelling too slowly and with this policy it will not since the cox will only speed up if the boat is in too low a gear.

\lstinputlisting[language=Java,caption={The implementation of the GearFocussed policy },label={listing:control:gear}]{code/GearFocussed.report.java}

\section{SafetyFocussed}

The SafetyFocussed policy's main aim is to avoid crashing. The implementation in Java is shown in Listing \ref{listing:control:safety}. It builds on the approach taken by the GearFocussed policy. However, ahead of the condition of travelling too slowly, this policy will check if the boat is close to a boat in front. If so this policy will cause the cox to slow down. This policy does not directly attempt to match the speed of any boat in front. But the interplay of the rules for slowing down if there's an obstruction ahead or speeding up if it's moving to slowly will cause the cox the match the speed on average although in bursts of repeated slowing down when it gets to close and then speeding up again in an attempt to match the cox's desired gear when the boat ahead has had to some time to move on a bit.

\lstinputlisting[language=Java,caption={The implementation of the SafetyFocussed policy },label={listing:control:safety}]{code/SafetyFocussed.report.java}

\section{Overtaking}

Neither of the GearFocussed or SafetyFocussed policies make any use of the middle lane. The Overtaking policy  attempts to correct this. The implementation in Java is shown in Listing \ref{listing:control:overtaking}. As with the other policies spinning is chosen if the river is about to run out to ensure it does not get stranded at the lock. Next it checks whether the policy is in overtaking mode and if so executes a subprogram to choose the action.

In overtaking mode, the cox will attempt to move back to the right as soon as it has completely moved into the middle lane and there are enough edges clear both ahead of it and behind it in the right-hand lane. Moving back to the right will terminate overtaking mode. Otherwise the cox will follow the GearFocussed approach of speeding up until the boat is in the cox's desired gear.

If the policy is not in overtaking mode, then if the cox is close to a boat ahead that is relatively moving sufficiently slower and the lane to the left is clear for a few edges ahead and behind, then this policy will move to the lane on the left (the middle lane) and enter overtaking mode. Otherwise the cox will follow the GearFocussed approach of speeding up until the boat is in the cox's desired gear.

The boat waits for the lane to be clear both in front and behind before moving over to the left or back to the right. This is a very simple way of avoiding a slow moving boat ahead (which may include a boat moving in the other direction) or a fast boat coming up behind. This is because there is no point trying to avoid a crash by pulling into a lane which is already occupied. The policy is a bit more aggressive about getting boats back to the right than initially pulling out. This is in the belief that it is best to leave this middle lane free for overtaking as much as possible. This is also why the policy requires a boat ahead to be moving sufficiently slowly compared to the cox's boat to avoid very long overtaking manoeuvres.


\lstinputlisting[language=Java,caption={The implementation of the Overtaking policy },label={listing:control:overtaking}]{code/Overtaking.report.java}

\section{Future Work}
There are a couple areas in which the control policies could be studied further.

\subsection{Improved policies}
Firstly it would be interesting to try a more intelligent Overtaking policy. A more advanced overtaking policy might check the speed of any boat in the lane it is moving to since a cox cannot crash into a boat ahead moving faster or a boat behind moving slower. It also looks symmetrically forwards and backwards. It might well make sense to look ahead further than behind since the boat is moving away from any obstructions behind. The current Overtaking policy also compares a cox's current speed with that of other boats. It might also pay to compare the cox's desired speed with other boats. This would allow a policy to stay safely behind a slow boat until there is room to overtake at which point it could accelerate again. Indeed it might even be an advantage for a cox to accelerate above its desired speed while overtaking in order to get by a slower boat and return to the right-hand lane more quickly.

The current policies could also spawn a new set of policies by playing with the parameters they use. For example, it would be interesting to see what the effect of reducing the distance SafetyFocussed policy leaves to the boat ahead or to try Overtaking policies that are more defensive about overtaking, waiting until the cox can see a long way ahead before pulling out.

\subsection{Machine learnt policies}\label{control:future:machinelearnt}
Creating more complex control policies by hand is a long process as each condition must be considered and implemented as a logical rules built out of observations. This is made harder as it the policies adding more rules quickly adds to the number of edge cases or can lead to undesired emergent behaviour when used by lots of coxes. These edge cases or bad behaviour may not be obvious from looking at the code. This means it is recommended to build the control policies up slowly and test them carefully using the simulation (for example by running the experiments in Chapter \ref{chapter:experiments}).

Using machine learning techniques to design new policies could carry some of this burden. Such policies may contain interesting new rules that a human would not think of. This is a large undertaking but one possible way would be to follow \textcite{Kochenderfer2003}. 

Kochenderfer shows how to use genetic programming to learn TR programs. The overall program and the conditions themselves are treated as trees. The conditions could be put together from the boolean observations and inequalities involving the numeric observations since these are all bounded (distances are bounded by the cox's vision and speeds are bounded by the top speed of a boat). The observation-based condition ``atoms" could then be combined with conjunction and negation operators to form more complex conditions.

The implementation would have be updated to turn a chromosomal representation of a policy into a working program in the application. The fitness function should promote policies that successful complete outings sticking close to their desired gear. The fitness function should also promote safety by promoting policies that cut down on the number and relative speed of any crash. The actually fitness function used would control how the safety of a policy is weighed against the policies attempt to stick to the outing plan.

This completes the look at the control policies. The next chapter will examine the data collected when running simulations using these policies.